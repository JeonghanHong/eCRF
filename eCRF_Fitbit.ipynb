{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMArC7CSm4cP+VCvKwQ0Sl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeonghanHong/eCRF/blob/main/eCRF_Fitbit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lmlm-wzZeMT5",
        "outputId": "94206d26-7c12-48c9-d143-8ac436d7eb2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok pandas matplotlib statsmodels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqepRvsyeQwL",
        "outputId": "69cbfbe8-aab8-4832-fc59-e6e216edd429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.31.0-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/8.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/8.4 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/8.4 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyngrok\n",
            "  Downloading pyngrok-7.1.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<8,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (7.0.1)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.0.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n",
            "Collecting validators<1,>=0.2 (from streamlit)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.11.4)\n",
            "Requirement already satisfied: patsy>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (0.5.6)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<8,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.17.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Installing collected packages: watchdog, validators, smmap, pyngrok, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.41 pydeck-0.8.1b0 pyngrok-7.1.0 smmap-5.0.1 streamlit-1.31.0 validators-0.22.0 watchdog-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# ngrok 인증 토큰 설정  2blRD9q8ERUslzqflw7XLOMdgqb_67NNKcTXEz9BYyBEBvUpy\n",
        "ngrok.set_auth_token(\"2blRD9q8ERUslzqflw7XLOMdgqb_67NNKcTXEz9BYyBEBvUpy\")\n",
        "\n",
        "# 이후 ngrok를 사용하여 터널 생성"
      ],
      "metadata": {
        "id": "Om6HQ5BoeQy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15419e4e-adae-43cf-81fe-c96b3ffb2483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "# 필요한 라이브러리 가져오기\n",
        "import streamlit as st\n",
        "import os\n",
        "from glob import glob\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from matplotlib.dates import AutoDateLocator\n",
        "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
        "\n",
        "# Directory path\n",
        "dir_path = '/content/drive/MyDrive/Fitbit/eCRF'\n",
        "\n",
        "# Retrieve all CSV filenames in the directory\n",
        "csv_files = glob(f'{dir_path}/S*.csv')\n",
        "\n",
        "all_subject_ids = [os.path.splitext(os.path.basename(f))[0] for f in csv_files]\n",
        "\n",
        "# Load the Demo.csv file\n",
        "demo_df = pd.read_csv('/content/drive/MyDrive/Fitbit/eCRF/Demo.csv')\n",
        "\n",
        "# Sidebar for user input\n",
        "with st.sidebar:\n",
        "    # Class selection\n",
        "    class_options = demo_df['Class'].unique()\n",
        "    selected_class = st.selectbox('Select Class', class_options)\n",
        "\n",
        "    # Filter demo_df based on selected Class\n",
        "    class_filtered_df = demo_df[demo_df['Class'] == selected_class]\n",
        "\n",
        "    # SubClass selection\n",
        "    subclass_options = class_filtered_df['SubClass'].unique()\n",
        "    selected_subclass = st.selectbox('Select SubClass', subclass_options)\n",
        "\n",
        "    # Filter class_filtered_df based on selected SubClass\n",
        "    subclass_filtered_df = class_filtered_df[class_filtered_df['SubClass'] == selected_subclass]\n",
        "\n",
        "    # Subject ID selection\n",
        "    selected_subject_ids = st.multiselect('Select Subject ID', subclass_filtered_df['Subject_ID'].tolist())\n",
        "\n",
        "    # Subject_ID 선택에 따른 Start Date와 End Date 디폴트 값 설정\n",
        "    if selected_subject_ids:\n",
        "        selected_demo_records = subclass_filtered_df[subclass_filtered_df['Subject_ID'].isin(selected_subject_ids)]\n",
        "\n",
        "        if not selected_demo_records.empty:\n",
        "            study_date = pd.to_datetime(selected_demo_records['Study_Date'].min())\n",
        "            start_date_default = study_date + pd.DateOffset(days=14)\n",
        "            end_date_default = study_date + pd.DateOffset(days=20)\n",
        "        else:\n",
        "            start_date_default = datetime.today()\n",
        "            end_date_default = datetime.today()\n",
        "    else:\n",
        "        start_date_default = datetime.today()\n",
        "        end_date_default = datetime.today()\n",
        "\n",
        "    # User input for the start date and end date\n",
        "    start_date = st.date_input(\"Select Start Date\", start_date_default)\n",
        "    end_date = st.date_input(\"Select End Date\", end_date_default)\n",
        "\n",
        "\n",
        "    # 나머지 코드...\n",
        "\n",
        "    # 날짜 입력 검증\n",
        "    if start_date > end_date:\n",
        "        st.error('End Date must be later than Start Date.')\n",
        "        st.stop()\n",
        "\n",
        "    # Slider for adjusting LOESS smoothing fraction\n",
        "    st.write('Adjust \"frac\" for LOESS smoothing (0.001 to 0.1)')\n",
        "    frac_value = st.slider(\"\", 0.001, 0.1, 0.05)\n",
        "\n",
        "# Add the following code to display the selected Subject ID's information\n",
        "if selected_subject_ids:\n",
        "    selected_demo_records = demo_df[demo_df['Subject_ID'].isin(selected_subject_ids)]\n",
        "\n",
        "    st.write(f\"Selected Subject IDs: {', '.join(selected_subject_ids)}\")\n",
        "    st.write(selected_demo_records)\n",
        "\n",
        "# Instructional message\n",
        "if not selected_subject_ids:\n",
        "    st.markdown(\"\"\"\n",
        "    **This application displays LOESS smoothed data for calories and HRV_Score and calculates the cross-correlation between these two time series.**\n",
        "\n",
        "    Please select 'Subject ID' from the left tab, and adjust the 'Start Date' and 'End Date' for the analysis, and \"frac\" for LOESS smoothing accordingly.\n",
        "\n",
        "    **Sidebar:**\n",
        "    - A date input widget labeled \"Select Start Date\" for the user to choose the starting date for the data analysis.\n",
        "    - A date input widget labeled \"Select End Date\" for the user to choose the ending date for the data analysis.\n",
        "    - A slider labeled \"Adjust 'frac' for LOESS smoothing (0.01 to 0.1)\" allowing the user to adjust the fraction for LOESS smoothing, with a range from 0.001 to 0.1 and a default value set at 0.05.\n",
        "    - A multi-select dropdown list labeled \"Select Subject ID\" populated with all the unique subject IDs. The user can select one or more subject IDs from this list for data analysis.\n",
        "\n",
        "    **Main Panel:**\n",
        "    - Initially, the main panel may not display any data until the user selects at least one Subject ID from the sidebar.\n",
        "    - Once the Subject IDs are selected, the main panel will display the DataFrame containing data corresponding to the selected Subject IDs and date range.\n",
        "    - After the data is loaded and filtered based on the user's selections, any further analysis or plots (like the LOESS smoothed time series or cross-correlation results) will be shown here as well.\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "    st.stop()\n",
        "\n",
        "# Load and concatenate selected data files\n",
        "selected_data_df = pd.DataFrame()\n",
        "for subject_id in selected_subject_ids:\n",
        "    file_path = f\"{dir_path}/{subject_id}.csv\"\n",
        "    temp_df = pd.read_csv(file_path, parse_dates=['DateTime'])\n",
        "\n",
        "    temp_df.rename(columns={\n",
        "        'Heart_Rat': 'Heart_Rate',\n",
        "        'SDNN': 'SDNN',\n",
        "        'RMSSD': 'RMSSD',\n",
        "        'Subject_ID_x': 'Subject_ID',\n",
        "        'VLF': 'VLF',\n",
        "        'LF': 'LF',\n",
        "        'HF': 'HF',\n",
        "        'LFHF_Ratio': 'LFHF_Ratio',\n",
        "        'Subject_ID_y': 'Subject_ID_y',\n",
        "        'Level_x': 'Activity',\n",
        "        'Mets': 'Mets',\n",
        "        'Value': 'Calories',\n",
        "        'Level_y': 'Sleep',\n",
        "    }, inplace=True)\n",
        "\n",
        "    selected_data_df = pd.concat([selected_data_df, temp_df], ignore_index=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define a mapping dictionary for Sleep quality\n",
        "sleep_mapping = {\n",
        "    '': -1,  # Add mapping for blank entries\n",
        "    'None': -1,\n",
        "    'restless': 0,\n",
        "    'wake': 1,\n",
        "    'asleep': 2,\n",
        "    'awake': 3,\n",
        "    'light': 4,\n",
        "    'rem': 5,\n",
        "    'deep': 6\n",
        "}\n",
        "\n",
        "# Map the Sleep column to numeric values based on the mapping\n",
        "selected_data_df['Sleep'] = selected_data_df['Sleep'].map(sleep_mapping).fillna(-1).astype(int)\n",
        "\n",
        "\n",
        "# Adjust the start_date and end_date to cover the entire day\n",
        "start_datetime = datetime.combine(start_date, datetime.min.time())\n",
        "end_datetime = datetime.combine(end_date, datetime.max.time())\n",
        "\n",
        "# Filter the data based on the selected date range including the time\n",
        "selected_data_df = selected_data_df[\n",
        "    (selected_data_df['DateTime'] >= start_datetime) &\n",
        "    (selected_data_df['DateTime'] <= end_datetime)\n",
        "]\n",
        "\n",
        "# Set 'DateTime' as index\n",
        "selected_data_df.set_index('DateTime', inplace=True)\n",
        "\n",
        "\n",
        "# 선택된 모든 subject_id에 대한 데이터 프레임을 기본적으로 표시\n",
        "for subject_id in selected_subject_ids:\n",
        "    st.write(f\"Data for Subject ID: {subject_id}\")\n",
        "    subject_data = selected_data_df[selected_data_df['Subject_ID'] == subject_id]\n",
        "    columns_to_display = [col for col in subject_data.columns if col not in ['Subject_ID', 'Subject_ID_y', 'Seconds']]\n",
        "    st.dataframe(subject_data[columns_to_display])\n",
        "\n",
        "\n",
        "\n",
        "# Optionally display the DataFrame without 'Subject_ID', 'Subject_ID_y', and 'Seconds' columns\n",
        "#if st.checkbox(\"Show DataFrame\"):\n",
        "#    for subject_id in selected_subject_ids:\n",
        "#        st.write(f\"Data for Subject ID: {subject_id}\")\n",
        "#        subject_data = selected_data_df[selected_data_df['Subject_ID'] == subject_id]\n",
        "#        columns_to_display = [col for col in subject_data.columns if col not in ['Subject_ID', 'Subject_ID_y', 'Seconds']]\n",
        "#        st.dataframe(subject_data[columns_to_display + ['Sleep']])  # Include the 'Sleep' column\n",
        "#else:\n",
        "#    # If \"Show DataFrame\" is not checked, display the combined DataFrame\n",
        "#    columns_to_display = [col for col in selected_data_df.columns if col not in ['Subject_ID', 'Subject_ID_y', 'Seconds']]\n",
        "#    st.dataframe(selected_data_df[columns_to_display])\n",
        "\n",
        "# Ensure the selected DataFrame has the necessary columns and is not empty\n",
        "if not selected_data_df.empty and {'RMSSD', 'Calories', 'Sleep'}.issubset(selected_data_df.columns):\n",
        "    # Apply LOESS smoothing to the selected data\n",
        "    hrv_score_lowess = lowess(selected_data_df['RMSSD'], mdates.date2num(selected_data_df.index), frac=frac_value)\n",
        "    calories_lowess = lowess(selected_data_df['Calories'], mdates.date2num(selected_data_df.index), frac=frac_value)\n",
        "\n",
        "    # Convert the lowess outputs to DataFrames\n",
        "    hrv_score_lowess_df = pd.DataFrame(hrv_score_lowess, columns=['DateTimeNum', 'HRV_Score_LOESS'])\n",
        "    hrv_score_lowess_df['DateTime'] = mdates.num2date(hrv_score_lowess_df['DateTimeNum'])\n",
        "    hrv_score_lowess_df.set_index('DateTime', inplace=True)\n",
        "\n",
        "    calories_lowess_df = pd.DataFrame(calories_lowess, columns=['DateTimeNum', 'Calories_LOESS'])\n",
        "    calories_lowess_df['DateTime'] = mdates.num2date(calories_lowess_df['DateTimeNum'])\n",
        "    calories_lowess_df.set_index('DateTime', inplace=True)\n",
        "\n",
        "\n",
        "    # UTC 시간대로 인덱스 변환 후 다시 로컬 시간대로 인덱스 변환\n",
        "    selected_data_df.index = selected_data_df.index.tz_localize('UTC')\n",
        "    selected_data_df.index = selected_data_df.index.tz_convert('Asia/Seoul')\n",
        "    # Combine the HRV Score and Calories DataFrames on their index\n",
        "    combined_df = hrv_score_lowess_df.join(calories_lowess_df['Calories_LOESS'])\n",
        "\n",
        "    # 'Sleep' 데이터를 'combined_df'에 추가\n",
        "    combined_df['Sleep'] = selected_data_df['Sleep']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Create two subplots vertically\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 14))\n",
        "\n",
        "    # First subplot for HRV Score vs. Calories\n",
        "    ax1.scatter(\n",
        "        combined_df.index,\n",
        "        combined_df['HRV_Score_LOESS'],\n",
        "        label='HRV Score (LOESS)',\n",
        "        color='darkblue',\n",
        "        alpha=0.5,\n",
        "        s=5\n",
        "    )\n",
        "    ax1.set_ylabel('HRV Score', color='darkblue')\n",
        "    ax1.tick_params(axis='y', labelcolor='darkblue')\n",
        "    ax1.set_title('HRV Score vs. Calories', fontsize=16)\n",
        "    ax1.xaxis.set_major_locator(AutoDateLocator(minticks=10, maxticks=20))\n",
        "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
        "    ax1.set_xlim(left=start_datetime)\n",
        "    ax1.legend(loc='upper left')\n",
        "    # 숨기기를 원하는 스파인 설정\n",
        "    ax1.spines['top'].set_visible(False)\n",
        "\n",
        "\n",
        "\n",
        "    # Create a secondary y-axis for the Calories data\n",
        "    ax1b = ax1.twinx()\n",
        "    ax1b.scatter(\n",
        "        combined_df.index,\n",
        "        combined_df['Calories_LOESS'],\n",
        "        label='Calories (LOESS)',\n",
        "        color='#654321',\n",
        "        alpha=0.5,\n",
        "        s=5\n",
        "    )\n",
        "    ax1b.set_ylabel('Calories', color='#654321')\n",
        "    ax1b.tick_params(axis='y', labelcolor='#654321')\n",
        "    ax1b.legend(loc='upper right')\n",
        "    # 숨기기를 원하는 스파인 설정\n",
        "    ax1b.spines['top'].set_visible(False)\n",
        "    # Second subplot for HRV Score vs. Sleep (with similar settings)\n",
        "    ax2.scatter(\n",
        "        combined_df.index,\n",
        "        combined_df['HRV_Score_LOESS'],\n",
        "        label='HRV Score (LOESS)',\n",
        "        color='darkblue',\n",
        "        alpha=0.5,\n",
        "        s=5\n",
        "    )\n",
        "    ax2.set_ylabel('HRV Score', color='darkblue')\n",
        "    ax2.tick_params(axis='y', labelcolor='darkblue')\n",
        "    ax2.set_title('HRV Score vs. Sleep', fontsize=16)\n",
        "    ax2.xaxis.set_major_locator(AutoDateLocator(minticks=10, maxticks=20))\n",
        "    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
        "    ax2.set_xlim(left=start_datetime)\n",
        "    ax2.legend(loc='upper left')\n",
        "    # 숨기기를 원하는 스파인 설정\n",
        "    ax2.spines['top'].set_visible(False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Create a secondary y-axis for the Sleep data\n",
        "    ax2b = ax2.twinx()\n",
        "    ax2b.scatter(\n",
        "        combined_df.index,\n",
        "        combined_df['Sleep'],\n",
        "        label='Sleep',\n",
        "        color='red',  # Sleep 색상 (red로 설정)\n",
        "        alpha=0.7,\n",
        "        s=3\n",
        "    )\n",
        "\n",
        "\n",
        "    ax2b.set_ylabel('Sleep', color='red')\n",
        "    ax2b.tick_params(axis='y', labelcolor='red')\n",
        "    ax2b.legend(loc='upper right')\n",
        "    # 숨기기를 원하는 스파인 설정\n",
        "    ax2b.spines['top'].set_visible(False)\n",
        "    ax2b.spines['bottom'].set_visible(False)\n",
        "    # Set y-axis limits for Sleep data\n",
        "    ax2b.set_ylim(-1, 6)  # Set the y-axis limits from -1 to 6\n",
        "\n",
        "    # Set y-axis tick positions and labels for Sleep data\n",
        "    sleep_labels = ['None', 'restless', 'wake', 'asleep', 'awake', 'light', 'rem', 'deep']\n",
        "    ax2b.set_yticks(range(-1, 7))  # Set the y-axis tick positions\n",
        "    ax2b.set_yticklabels(sleep_labels)  # Set the y-axis tick labels to sleep_labels\n",
        "\n",
        "    # Remove grid from both subplots\n",
        "    ax1.grid(False)\n",
        "    ax2.grid(False)\n",
        "    ax2.spines['top'].set_visible(False)\n",
        "\n",
        "    # Format the plot\n",
        "    fig.autofmt_xdate(rotation=90)\n",
        "    plt.tight_layout()  # Adjust the layout\n",
        "    # Display the plot in Streamlit\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    # Define a function to calculate cross-correlation\n",
        "    def cross_correlation(timeseries1, timeseries2, lag=24, plot=True):\n",
        "        ccf = [timeseries1.corr(timeseries2.shift(t)) for t in range(-lag, lag+1)]\n",
        "        if plot:\n",
        "            fig, ax = plt.subplots(figsize=(12, 5))\n",
        "            ax.plot(range(-lag, lag+1), ccf)\n",
        "            ax.axhline(0, linestyle='--', color='k')\n",
        "            ax.axvline(0, linestyle='--', color='k')\n",
        "            ax.set_title('Investigating Lead-Lag Dynamics Between Calories and HRV Score Over 6 Hours')\n",
        "            ax.set_xlabel('Lag in 5-minute intervals')\n",
        "            ax.set_ylabel('Correlation coefficient')\n",
        "            st.pyplot(fig)\n",
        "        return ccf\n",
        "\n",
        "    # Define the interpret_correlation function\n",
        "    def interpret_correlation(max_corr, lag, leading_var, lagged_var, interval_minutes=5):\n",
        "        time_diff = abs(lag) * interval_minutes\n",
        "\n",
        "        if lag > 0:\n",
        "            relationship = f\"{lagged_var} increases, followed by an increase in {leading_var} after approximately {time_diff} minutes.\"\n",
        "        elif lag < 0:\n",
        "            relationship = f\"{leading_var} increases, followed by an increase in {lagged_var} after approximately {time_diff} minutes.\"\n",
        "        else:\n",
        "            relationship = \"both variables change simultaneously.\"\n",
        "\n",
        "        interpretation = (\n",
        "            f\"The maximum cross-correlation value is {max_corr:.4f}, occurring at a lag of {lag} intervals. \"\n",
        "            f\"This suggests that {relationship}\"\n",
        "        )\n",
        "        return interpretation\n",
        "\n",
        "    # Calculate cross-correlation and capture the result\n",
        "    cross_correlation_result = cross_correlation(combined_df['Calories_LOESS'], combined_df['HRV_Score_LOESS'], lag=24)\n",
        "\n",
        "    # Find the index of the maximum correlation coefficient in the result\n",
        "    max_corr_index = max(range(len(cross_correlation_result)), key=lambda index: abs(cross_correlation_result[index]))\n",
        "    max_corr_value = cross_correlation_result[max_corr_index]\n",
        "    max_lag = max_corr_index - 24\n",
        "\n",
        "    if max_lag > 0:\n",
        "        leading = \"HRV_Score\"\n",
        "        lagged = \"Calories\"\n",
        "    elif max_lag < 0:\n",
        "        leading = \"Calories\"\n",
        "        lagged = \"HRV_Score\"\n",
        "    else:\n",
        "        leading = lagged = \"none; the variables change simultaneously\"\n",
        "\n",
        "    interpretation = interpret_correlation(max_corr_value, max_lag, leading, lagged)\n",
        "    st.write(f\"Maximum cross-correlation value: {max_corr_value:.4f} at lag: {max_lag}\")\n",
        "    st.write(f\"Leading variable: {leading}\")\n",
        "    st.write(f\"Lagged variable: {lagged}\")\n",
        "    st.write(interpretation)\n",
        "\n",
        "\n",
        "\n",
        "#........Insights...................................................................................\n",
        "\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import pytz  # Import the pytz library for timezone conversion\n",
        "\n",
        "# Load your data into combined_df and set start_datetime and end_datetime\n",
        "\n",
        "# Calculate the total time spent in deep sleep (assuming your Sleep column has values 6 for deep sleep)\n",
        "total_deep_sleep_time = combined_df['Sleep'][combined_df['Sleep'] == 6].count() * 5  # Assuming 5 minutes per interval\n",
        "\n",
        "# Calculate the total time within the selected time range\n",
        "total_selected_time = (end_datetime - start_datetime).total_seconds() / 3600  # Convert to hours\n",
        "\n",
        "# Calculate the maximum and minimum values for HRV (RMSSD) and Calories\n",
        "max_hrv = combined_df['HRV_Score_LOESS'].max()\n",
        "min_hrv = combined_df['HRV_Score_LOESS'].min()\n",
        "max_calories = combined_df['Calories_LOESS'].max()\n",
        "min_calories = combined_df['Calories_LOESS'].min()\n",
        "\n",
        "# Calculate the deep sleep percentage for each hour interval\n",
        "hourly_deep_sleep_percentage = []\n",
        "for hour in range(24):\n",
        "    hour_start = start_datetime.replace(hour=hour, minute=0, second=0)\n",
        "    hour_end = start_datetime.replace(hour=hour, minute=59, second=59)\n",
        "\n",
        "    # Convert hour_start and hour_end to 'Asia/Seoul' timezone\n",
        "    seoul_timezone = pytz.timezone('Asia/Seoul')\n",
        "    hour_start_seoul = hour_start.astimezone(seoul_timezone)\n",
        "    hour_end_seoul = hour_end.astimezone(seoul_timezone)\n",
        "\n",
        "    hour_data = combined_df[(combined_df.index >= hour_start_seoul) & (combined_df.index <= hour_end_seoul)]\n",
        "\n",
        "    # Calculate deep sleep percentage for this hour\n",
        "    deep_sleep_time = hour_data['Sleep'][hour_data['Sleep'] == 6].count() * 5\n",
        "    hour_percentage = (deep_sleep_time / 60) * 100  # Assuming 60 minutes in an hour\n",
        "    hourly_deep_sleep_percentage.append(hour_percentage)\n",
        "\n",
        "# Find the hour with the highest deep sleep percentage\n",
        "max_deep_sleep_hour = hourly_deep_sleep_percentage.index(max(hourly_deep_sleep_percentage))\n",
        "max_deep_sleep_percentage = max(hourly_deep_sleep_percentage)\n",
        "\n",
        "# Find the time when maximum and minimum HRV (RMSSD) values occurred\n",
        "max_hrv_time = combined_df[combined_df['HRV_Score_LOESS'] == max_hrv].index[0]\n",
        "min_hrv_time = combined_df[combined_df['HRV_Score_LOESS'] == min_hrv].index[0]\n",
        "\n",
        "# Find the time when maximum and minimum Calories values occurred\n",
        "max_calories_time = combined_df[combined_df['Calories_LOESS'] == max_calories].index[0]\n",
        "min_calories_time = combined_df[combined_df['Calories_LOESS'] == min_calories].index[0]\n",
        "\n",
        "# Convert timestamps to 'Asia/Seoul' timezone\n",
        "seoul_timezone = pytz.timezone('Asia/Seoul')\n",
        "max_hrv_time_seoul = max_hrv_time.astimezone(seoul_timezone)\n",
        "min_hrv_time_seoul = min_hrv_time.astimezone(seoul_timezone)\n",
        "max_calories_time_seoul = max_calories_time.astimezone(seoul_timezone)\n",
        "min_calories_time_seoul = min_calories_time.astimezone(seoul_timezone)\n",
        "\n",
        "# Calculate the corresponding hour start and end times\n",
        "max_deep_sleep_hour_start = start_datetime.replace(hour=max_deep_sleep_hour, minute=0, second=0)\n",
        "max_deep_sleep_hour_end = start_datetime.replace(hour=max_deep_sleep_hour, minute=59, second=59)\n",
        "\n",
        "# Convert hour start and end times to 'Asia/Seoul' timezone\n",
        "max_deep_sleep_hour_start_seoul = max_deep_sleep_hour_start.astimezone(seoul_timezone)\n",
        "max_deep_sleep_hour_end_seoul = max_deep_sleep_hour_end.astimezone(seoul_timezone)\n",
        "\n",
        "\n",
        "# Create a DataFrame to organize the results\n",
        "results_data = {\n",
        "    \"Metric\": [\"HRV Max at\", \"HRV Min at\", \"Calories Max at\", \"Calories Min at\", \"Most Deep Sleep % at\"],\n",
        "    \"When\": [max_hrv_time_seoul.strftime('%Y-%m-%d %H:%M'), min_hrv_time_seoul.strftime('%Y-%m-%d %H:%M'), max_calories_time_seoul.strftime('%Y-%m-%d %H:%M'), min_calories_time_seoul.strftime('%Y-%m-%d %H:%M'), f\"{max_deep_sleep_hour_start_seoul.strftime('%Y-%m-%d %H:%M')} - {max_deep_sleep_hour_end_seoul.strftime('%Y-%m-%d %H:%M')}\"],\n",
        "    \"Value\": [f\"{max_hrv:.4f}\", f\"{min_hrv:.4f}\", f\"{max_calories:.4f}\", f\"{min_calories:.4f}\", f\"{max_deep_sleep_percentage:.4f}%\"]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "results_df = pd.DataFrame(results_data)\n",
        "\n",
        "# Display the results in a table with download, search, and expand capabilities\n",
        "st.write(\"##### Insights:\")\n",
        "st.dataframe(results_df)\n",
        "\n",
        "\n",
        "# ..........HRV Metrics....................................................\n",
        "\n",
        "# 'DateTime' 열을 이미 앞에서 인덱스로 설정\n",
        "\n",
        "\n",
        "# Define the classification logic\n",
        "def determine_patient_status(row):\n",
        "    # 스트레스 상태 판별\n",
        "    if row['RMSSD'] < 30:\n",
        "        stress_status = \"Low Stress\"  # 저 스트레스\n",
        "    else:\n",
        "        stress_status = \"High Stress\"  # 고 스트레스\n",
        "\n",
        "    # 신경계 판별 (Nervous System Status)\n",
        "    if row['LFHF_Ratio'] > 1.5:\n",
        "        nervous_system_status = \"Sympathetic Dominance\"  # 교감신경우세\n",
        "    elif row['LFHF_Ratio'] < 0.5:\n",
        "        nervous_system_status = \"Parasympathetic Dominance\"  # 부교감신경우세\n",
        "    else:\n",
        "        nervous_system_status = \"Balanced Autonomic\"  # 균형잡힌 자율신경계\n",
        "\n",
        "    return stress_status, nervous_system_status\n",
        "\n",
        "# 'DateTime' 열을 인덱스로 유지하면서 상태 분류 적용\n",
        "selected_data_df[['Stress Status', 'Nervous System Status']] = selected_data_df.apply(\n",
        "    lambda row: pd.Series(determine_patient_status(row)), axis=1\n",
        ")\n",
        "\n",
        "final_df = selected_data_df\n",
        "\n",
        "\n",
        "# Streamlit app code\n",
        "columns_to_display = ['Stress Status', 'Nervous System Status', 'Heart_Rate', 'SDNN', 'RMSSD', 'VLF', 'LF', 'HF', 'LFHF_Ratio']\n",
        "\n",
        "# 소수점 네 번째 자리까지 표시하도록 옵션 설정\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "st.write(\"##### HRV Metrics:\")\n",
        "st.dataframe(final_df[columns_to_display])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#------Stress Analytics-------------------------------------------------------------------------\n",
        "\n",
        "# Define the URL for the image\n",
        "image_url = \"https://raw.githubusercontent.com/JeonghanHong/eCRF/main/stress.png\"\n",
        "\n",
        "def get_transition_message(stress_status_before, nervous_system_status_before, stress_status_after, nervous_system_status_after):\n",
        "    # Define messages for each case, with corrections\n",
        "    messages = {\n",
        "        ('Low Stress', 'Parasympathetic Dominance', 'High Stress', 'Sympathetic Dominance'):\n",
        "        \"\"\"Change from [Low Stress and Parasympathetic Dominance] to [High Stress and Sympathetic Dominance]\n",
        "\n",
        "Cause: Tension, stress, or sudden psychological shock.\n",
        "\n",
        "Diagnosis: Stress levels increase with activation of the sympathetic nervous system, leading to a heightened state of tension in the body.\n",
        "\n",
        "Prescription: The use of Theanine and Tryptophan can aid in stress management and tension relief. Additionally, supplementing with Pyridoxine (Vitamin B6) can enhance stress management and improve nerve function.\n",
        "\n",
        "These measures serve as general guidelines for managing stress and maintaining physical well-being. However, it is important to consult with a healthcare professional for personalized advice based on individual circumstances and needs.\"\"\",\n",
        "\n",
        "        ('Low Stress', 'Sympathetic Dominance', 'High Stress', 'Sympathetic Dominance'):\n",
        "        \"\"\"Change from [Low Stress and Sympathetic Dominance] to [High Stress and Sympathetic Dominance]\n",
        "\n",
        "Cause: Sudden stressors, tension, or urgent situations.\n",
        "\n",
        "Diagnosis: Stress levels increase with activation of the sympathetic nervous system, resulting in heightened alertness and tension.\n",
        "\n",
        "Prescription: Theanine can be used to alleviate stress and tension and prepare for acute stress situations. Additionally, supplementing with Magnesium and Potassium can support the sympathetic nervous system and promote overall bodily stability.\n",
        "\n",
        "These measures serve as general guidelines for managing stress and maintaining physical well-being. However, it is important to consult with a healthcare professional for personalized advice based on individual circumstances and needs.\"\"\",\n",
        "\n",
        "        # Add the image URL here for the specific case\n",
        "        ('Low Stress', 'Sympathetic Dominance', 'High Stress', 'Parasympathetic Dominance'):\n",
        "        f\"\"\"Change from [Low Stress and Sympathetic Dominance] to [High Stress and Parasympathetic Dominance]\n",
        "\n",
        "Cause: Sudden stressful situations, tension, or urgent scenarios.\n",
        "\n",
        "Diagnosis: Stress levels increase with activation of the sympathetic nervous system, transitioning to an activated parasympathetic nervous system, inducing a state of relaxation.\n",
        "\n",
        "Prescription: The use of Theanine, Tryptophan, and Tyrosine can stabilize emotions during stress and activate the parasympathetic nervous system. Additionally, supplementing with Iodine, Zinc, and Manganese can maintain mineral balance and support metabolism.\n",
        "\n",
        "These measures serve as general guidelines for managing stress and maintaining physical well-being. However, it is important to consult with a healthcare professional for personalized advice based on individual circumstances and needs.\"\"\",\n",
        "\n",
        "        ('Low Stress', 'Balanced Autonomic', 'High Stress', 'Parasympathetic Dominance'):\n",
        "        \"\"\"Change from [Low Stress and Balanced Autonomic] to [High Stress and Parasympathetic Dominance]\n",
        "\n",
        "Cause: Tension, stress, or sudden psychological shock.\n",
        "\n",
        "Diagnosis: Stress levels increase dramatically with activation of the parasympathetic nervous system, inhibiting the transition to a state of rest and instead leading to increased secretion of pancreatic cells.\n",
        "\n",
        "Prescription: To aid in stress management and tension relief, Theanine and Tryptophan can be utilized. Additionally, supplementing with Iodine, Zinc, and Manganese can support mineral balance and metabolism.\n",
        "\n",
        "These measures serve as general guidelines for managing stress and maintaining physical well-being. However, it is important to consult with a healthcare professional for personalized advice based on individual circumstances and needs.\"\"\",\n",
        "\n",
        "        ('Low Stress', 'Balanced Autonomic', 'High Stress', 'Sympathetic Dominance'):\n",
        "        \"\"\"Change from [Low Stress and Balanced Autonomic] to [High Stress and Sympathetic Dominance]\n",
        "\n",
        "Cause: Sudden stressors, tension, or urgent situations.\n",
        "\n",
        "Diagnosis: Stress levels increase significantly with activation of the sympathetic nervous system, leading to a state of heightened physical activity instead of relaxation.\n",
        "\n",
        "Prescription: To prepare for acute stress situations, Theanine can be used to alleviate stress and tension. Supplementing with Magnesium and Potassium can support the sympathetic nervous system and promote overall bodily stability.\n",
        "\n",
        "These measures serve as general guidelines for managing stress and maintaining physical well-being. However, it is important to consult with a healthcare professional for personalized advice based on individual circumstances and needs.\"\"\",\n",
        "    }\n",
        "\n",
        "    # Lookup the message based on the transition\n",
        "    key = (stress_status_before, nervous_system_status_before, stress_status_after, nervous_system_status_after)\n",
        "    message = messages.get(key, \"No specific case matched.\")\n",
        "\n",
        "    # Add the image to the message if it's one of the specified cases\n",
        "    if key in messages:\n",
        "        st.image(image_url, caption=\"Stress Image\", use_column_width=True)\n",
        "\n",
        "    return message\n",
        "\n",
        "# Call the function to display the message with the image for the specified case\n",
        "#message = get_transition_message('Low Stress', 'Sympathetic Dominance', 'High Stress', 'Parasympathetic Dominance')\n",
        "\n",
        "# Display the message\n",
        "#st.write(message)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def detect_and_display_transitions(df):\n",
        "    previous_status = ('', '')\n",
        "    transition_start_time = None\n",
        "    longest_transition = None\n",
        "    longest_duration = timedelta(0)\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        current_status = (row['Stress Status'], row['Nervous System Status'])\n",
        "\n",
        "        # Start tracking a new transition\n",
        "        if current_status == ('High Stress', 'Sympathetic Dominance') and previous_status == ('Low Stress', 'Sympathetic Dominance'):\n",
        "            transition_start_time = index  # Update the start time of the transition\n",
        "\n",
        "        # Check if the current status is different from the target transition status\n",
        "        elif current_status != ('High Stress', 'Sympathetic Dominance') and transition_start_time:\n",
        "            duration = index - transition_start_time\n",
        "            if duration > longest_duration:\n",
        "                longest_duration = duration\n",
        "                longest_transition = (transition_start_time, index, longest_duration)\n",
        "            transition_start_time = None  # Reset start time for next transition\n",
        "\n",
        "        previous_status = current_status\n",
        "\n",
        "    if longest_transition:\n",
        "        start, end, duration = longest_transition\n",
        "        st.write(f\"Significant state transition detected from {start} to {end}, lasting {duration}.\")\n",
        "        # Assuming you have a predefined function to get a transition message\n",
        "        transition_message = get_transition_message('Low Stress', 'Sympathetic Dominance', 'High Stress', 'Sympathetic Dominance')\n",
        "        st.markdown(transition_message)\n",
        "    else:\n",
        "        st.write(\"No significant state transition was detected.\")\n",
        "\n",
        "# Assuming selected_data_df is a DataFrame structured with the necessary columns\n",
        "detect_and_display_transitions(selected_data_df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#.....Sleep_metrics................................................\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "from datetime import datetime, timedelta, time\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "from datetime import datetime, timedelta, time\n",
        "\n",
        "# Define the boundary for a new day and inactive hours\n",
        "day_start_hour = 9\n",
        "inactive_start, inactive_end = time(9, 0), time(21, 0)\n",
        "\n",
        "\n",
        "\n",
        "# Function to assign session ids based on transitions, considering inactive periods\n",
        "def assign_sleep_sessions(sleep_data, index):\n",
        "    sleep_sessions = []\n",
        "    session_id = 0\n",
        "    for i, (timestamp, sleep_state) in enumerate(zip(index, sleep_data)):\n",
        "        # Increment session_id at the start of a new sleep period\n",
        "        if i > 0 and sleep_state != -1 and sleep_data[i - 1] == -1:\n",
        "            session_id += 1\n",
        "        # Consider inactive hours as separate 'sessions'\n",
        "        if inactive_start <= timestamp.time() <= inactive_end:\n",
        "            session_id += 1\n",
        "        sleep_sessions.append(session_id)\n",
        "    return sleep_sessions\n",
        "\n",
        "# Adjust day based on a 09:00 threshold\n",
        "def get_sleep_day(dt):\n",
        "    if dt.time() < inactive_start:\n",
        "        return (dt - timedelta(days=1)).date()\n",
        "    return dt.date()\n",
        "\n",
        "# Main function to calculate sleep metrics\n",
        "def calculate_sleep_metrics(df):\n",
        "    df = df.copy()\n",
        "    if 'Seconds' in df.columns:\n",
        "        df = df.drop(columns=['Seconds'])\n",
        "    df.index = pd.to_datetime(df.index).tz_localize(None)\n",
        "    df['Sleep_Session'] = assign_sleep_sessions(df['Sleep'], df.index)\n",
        "    df['Sleep_Day'] = df.index.map(get_sleep_day)\n",
        "    daily_sleep_metrics = []\n",
        "\n",
        "    for sleep_day, day_group in df.groupby('Sleep_Day'):\n",
        "        filtered_group = day_group[(day_group.index.time < inactive_start) | (day_group.index.time > inactive_end)]\n",
        "        for session, session_group in filtered_group.groupby('Sleep_Session'):\n",
        "            if session_group.empty:\n",
        "                continue\n",
        "            nominal_sleep_duration_minutes = session_group.index.to_series().diff().dt.total_seconds().dropna().sum() / 60\n",
        "            net_sleep_duration_minutes = session_group[~session_group['Sleep'].isin([0, 1, 2, 3])].index.to_series().diff().dt.total_seconds().dropna().sum() / 60\n",
        "            sleep_efficiency = (net_sleep_duration_minutes / nominal_sleep_duration_minutes) * 100 if nominal_sleep_duration_minutes > 0 else 0\n",
        "            deep_sleep = session_group[session_group['Sleep'] == 6].index.to_series().diff().dt.total_seconds().sum() / 60\n",
        "            rem_sleep = session_group[session_group['Sleep'] == 5].index.to_series().diff().dt.total_seconds().sum() / 60\n",
        "            light_sleep = session_group[session_group['Sleep'] == 4].index.to_series().diff().dt.total_seconds().sum() / 60\n",
        "            total_measured_sleep = deep_sleep + rem_sleep + light_sleep\n",
        "            deep_percentage = (deep_sleep / total_measured_sleep * 100) if total_measured_sleep > 0 else 0\n",
        "            rem_percentage = (rem_sleep / total_measured_sleep * 100) if total_measured_sleep > 0 else 0\n",
        "            light_percentage = (light_sleep / total_measured_sleep * 100) if total_measured_sleep > 0 else 0\n",
        "            daily_sleep_metrics.append({\n",
        "                'Date': sleep_day,\n",
        "                'Nominal Sleep (min)': nominal_sleep_duration_minutes,\n",
        "                'Net Sleep (min)': net_sleep_duration_minutes,\n",
        "                'Sleep Efficiency (%)': f\"{sleep_efficiency:.2f}\",\n",
        "                'Sleep Composition (Deep:REM:Light)': f\"{deep_percentage:.0f}%:{rem_percentage:.0f}%:{light_percentage:.0f}%\"\n",
        "            })\n",
        "    return pd.DataFrame(daily_sleep_metrics)\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "\n",
        "# Analyze sleep data function\n",
        "def analyze_sleep_data(df):\n",
        "    # Calculate averages and distributions\n",
        "    average_nominal_sleep = df['Nominal Sleep (min)'].mean()\n",
        "    average_net_sleep = df['Net Sleep (min)'].mean()\n",
        "    avg_nominal_hrs, avg_nominal_mins = divmod(average_nominal_sleep, 60)\n",
        "    avg_net_hrs, avg_net_mins = divmod(average_net_sleep, 60)\n",
        "    min_sleep = df['Net Sleep (min)'].min()\n",
        "    max_sleep = df['Net Sleep (min)'].max()\n",
        "\n",
        "    # Convert sleep efficiency percentages to numeric, skipping NA\n",
        "    df['Sleep Efficiency (%)'] = pd.to_numeric(df['Sleep Efficiency (%)'].str.replace('%', ''), errors='coerce')\n",
        "    average_efficiency = df['Sleep Efficiency (%)'].mean(skipna=True)\n",
        "\n",
        "    # Process sleep composition\n",
        "    sleep_composition = df['Sleep Composition (Deep:REM:Light)'].str.replace('%', '').str.split(':', expand=True).apply(pd.to_numeric, errors='coerce')\n",
        "    avg_deep, avg_rem, avg_light = sleep_composition.mean()\n",
        "\n",
        "    # Prepare interpretation string\n",
        "    interpretation = \"\"\"\n",
        "    [Sleep Duration] During the observed period, the average nominal sleep duration was {0} hours and {1} minutes, with a sleep time distribution ranging from {2} to {3} minutes.<br><br>\n",
        "    [Sleep Efficiency] The average sleep efficiency was {4:.2f}%, which is generally considered good.<br><br>\n",
        "    [Sleep Composition] However, the average sleep composition ratios of Deep:REM:Light were {5:.0f}%:{6:.0f}%:{7:.0f}%, indicating a lower than ideal proportion of deep to REM sleep according to standard sleep criteria.\n",
        "    \"\"\".format(int(avg_nominal_hrs), int(avg_nominal_mins), min_sleep, max_sleep, average_efficiency, avg_deep, avg_rem, avg_light)\n",
        "\n",
        "    # Display the interpretation in Streamlit\n",
        "    st.markdown(interpretation, unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "\n",
        "# Calculate sleep metrics\n",
        "daily_sleep_metrics_df = calculate_sleep_metrics(combined_df)\n",
        "\n",
        "# Assuming daily_sleep_metrics_df is the DataFrame containing all the metrics you've calculated\n",
        "filtered_daily_sleep_metrics_df = daily_sleep_metrics_df[\n",
        "    ~((daily_sleep_metrics_df['Sleep Composition (Deep:REM:Light)'] == '0%:0%:0%') )\n",
        "]\n",
        "\n",
        "filtered_daily_sleep_metrics_df = filtered_daily_sleep_metrics_df.reset_index(drop=True)\n",
        "\n",
        "# Now display the DataFrame without the index\n",
        "st.write(\"##### Sleep Metrics:\")\n",
        "st.dataframe(filtered_daily_sleep_metrics_df)\n",
        "\n",
        "# Call the function to analyze the sleep data\n",
        "analyze_sleep_data(filtered_daily_sleep_metrics_df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#------- Sleep Analytics Graph-----------------------------------------------------------------------------------------\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure 'Date' is a datetime object and set as index\n",
        "if not isinstance(daily_sleep_metrics_df.index, pd.DatetimeIndex):\n",
        "    daily_sleep_metrics_df['Date'] = pd.to_datetime(daily_sleep_metrics_df['Date'])\n",
        "    daily_sleep_metrics_df.set_index('Date', inplace=True)\n",
        "\n",
        "# Filter out dates where 'Nominal Sleep (min)' is 200 minutes or less\n",
        "filtered_df = daily_sleep_metrics_df[daily_sleep_metrics_df['Nominal Sleep (min)'] > 200]\n",
        "\n",
        "# Create a new figure and axis object\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot Nominal Sleep\n",
        "ax.bar(filtered_df.index, filtered_df['Nominal Sleep (min)'], label='Nominal Sleep (min)', color='skyblue')\n",
        "\n",
        "# Plot Net Sleep within Nominal Sleep\n",
        "ax.bar(filtered_df.index, filtered_df['Net Sleep (min)'], label='Net Sleep (min)', color='blue')\n",
        "\n",
        "# Customize the x-axis to show both date and day of the week\n",
        "ax.set_xticks(filtered_df.index)\n",
        "ax.set_xticklabels(filtered_df.index.strftime('%Y-%m-%d (%a)'), rotation=90, ha='right')\n",
        "\n",
        "# Set the labels and title\n",
        "ax.set_xlabel('Date and Day of the Week')\n",
        "ax.set_ylabel('Sleep (min)')\n",
        "ax.set_title('Sleep Analysis')\n",
        "\n",
        "# Add a legend\n",
        "ax.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "st.pyplot(fig)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqOGUoN56hJm",
        "outputId": "e736cf77-9a5c-4c00-9827-b7c5f0895829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup streamlit run app.py &\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# 기존 터널이 있다면 종료\n",
        "ngrok.kill()\n",
        "\n",
        "# Streamlit이 사용하는 포트 (기본값: 8501)에 대한 퍼블릭 URL 생성\n",
        "public_url = ngrok.connect(\"8501\")\n",
        "print(\"Streamlit 애플리케이션의 퍼블릭 URL:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsK_dA8IeQ_f",
        "outputId": "2772ef71-7131-454e-8015-cd7849000d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "Streamlit 애플리케이션의 퍼블릭 URL: NgrokTunnel: \"https://5e07-34-86-152-4.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok diagnose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYdTm3LeJZ-K",
        "outputId": "db33baf1-93c7-4301-dd71-dff056fb736d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing ngrok connectivity...\n",
            "\n",
            "Internet Connectivity\n",
            "  Name Resolution                           [ OK ]\n",
            "  TCP                                       [ OK ]\n",
            "  TLS                                       [ OK ]\n",
            "Localhost Connectivity\n",
            "  Name Resolution                           [ OK ]\n",
            "Ngrok Connectivity - Region: United States\n",
            "  Name Resolution                           [ OK ]\n",
            "  TCP                                       [ OK ]\n",
            "  TLS                                       [ OK ]\n",
            "  Tunnel Protocol                           [ OK ]\n",
            "Successfully established ngrok connection! (region: 'us', latency: 30.082413ms)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}